{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "167a2a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos MNIST...\n",
      "Datos MNIST cargados exitosamente.\n",
      "----------------------------------------\n",
      "Arquitectura MLP: 784 --> 512 neuronas (Oculta) --> 10 neuronas (Salida).\n",
      "----------------------------------------\n",
      "\n",
      "--- Inicio del Entrenamiento OpenMP ---\n",
      "Arquitectura MLP: 784 --> 512 neuronas --> 10 neuronas\n",
      "Epoch 1/10 - Loss: 0.6689 - Acc: 84.13% - Tiempo: 31.88s\n",
      "Epoch 2/10 - Loss: 0.3511 - Acc: 90.32% - Tiempo: 24.51s\n",
      "Epoch 3/10 - Loss: 0.3000 - Acc: 91.58% - Tiempo: 23.38s\n",
      "Epoch 4/10 - Loss: 0.2690 - Acc: 92.50% - Tiempo: 25.86s\n",
      "Epoch 5/10 - Loss: 0.2459 - Acc: 93.18% - Tiempo: 25.09s\n",
      "Epoch 6/10 - Loss: 0.2273 - Acc: 93.71% - Tiempo: 23.91s\n",
      "Epoch 7/10 - Loss: 0.2117 - Acc: 94.15% - Tiempo: 23.80s\n",
      "Epoch 8/10 - Loss: 0.1984 - Acc: 94.54% - Tiempo: 26.13s\n",
      "Epoch 9/10 - Loss: 0.1868 - Acc: 94.84% - Tiempo: 28.57s\n",
      "Epoch 10/10 - Loss: 0.1765 - Acc: 95.13% - Tiempo: 29.49s\n",
      "\n",
      "----------------------------------------\n",
      "Entrenamiento Finalizado.\n",
      "Tiempo Total OpenMP: 262.62 segundos\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 8 hilos\n",
    "!gcc mlp_openmp.c -o mlp_openmp -lm -mavx2 -mfma -fopenmp\n",
    "!export OMP_NUM_THREADS=8 && ./mlp_openmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0effc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mlp_openmp.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile mlp_openmp.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <string.h>\n",
    "#include <omp.h>       // ¡Librería OpenMP!\n",
    "#include <immintrin.h> // Librería para intrínsecos AVX\n",
    "\n",
    "// --- CONSTANTES DE LA RED ---\n",
    "#define INPUT_SIZE 784\n",
    "#define HIDDEN_SIZE 512   // Capa oculta de 512 neuronas\n",
    "#define OUTPUT_SIZE 10\n",
    "#define M_TRAIN 60000    \n",
    "#define BATCH_SIZE 64    \n",
    "#define EPOCHS 10        \n",
    "#define LR 0.01\n",
    "\n",
    "// Archivos de datos \n",
    "#define TRAIN_X_PATH \"data/X_train.bin\"\n",
    "#define TRAIN_Y_PATH \"data/Y_train.bin\"\n",
    "\n",
    "// Constante para el ancho de vector AVX2 (4 doubles por registro __m256d)\n",
    "#define AVX_DOUBLE_WIDTH 4\n",
    "\n",
    "// --- ESTRUCTURA Y UTILERÍAS ---\n",
    "// ... (load_data, init_xavier, init_params, hsum_avx, relu, softmax, one_hot, etc. son las mismas) ...\n",
    "\n",
    "typedef struct {\n",
    "    double* W1;\n",
    "    double* b1;\n",
    "    double* W2;\n",
    "    double* b2;\n",
    "} Params;\n",
    "\n",
    "double get_time_diff(clock_t start, clock_t end) {\n",
    "    return (double)(end - start) / CLOCKS_PER_SEC;\n",
    "}\n",
    "\n",
    "void load_data(double* X, int* Y) {\n",
    "    FILE *f_x = fopen(TRAIN_X_PATH, \"rb\");\n",
    "    FILE *f_y = fopen(TRAIN_Y_PATH, \"rb\");\n",
    "\n",
    "    if (f_x == NULL || f_y == NULL) {\n",
    "        fprintf(stderr, \"Error: No se encuentran los archivos .bin.\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "    fread(X, sizeof(double), INPUT_SIZE * M_TRAIN, f_x);\n",
    "    fread(Y, sizeof(int), M_TRAIN, f_y);\n",
    "    fclose(f_x);\n",
    "    fclose(f_y);\n",
    "    printf(\"Datos MNIST cargados exitosamente.\\n\");\n",
    "}\n",
    "\n",
    "void init_xavier(double* W, int n_in, int n_out) {\n",
    "    double limit = sqrt(6.0 / (n_in + n_out));\n",
    "    for (int i = 0; i < n_in * n_out; i++) {\n",
    "        W[i] = ((double)rand() / RAND_MAX) * 2 * limit - limit;\n",
    "    }\n",
    "}\n",
    "\n",
    "Params init_params() {\n",
    "    Params p;\n",
    "    srand(42); \n",
    "    p.W1 = (double*)malloc(HIDDEN_SIZE * INPUT_SIZE * sizeof(double));\n",
    "    p.b1 = (double*)calloc(HIDDEN_SIZE, sizeof(double));\n",
    "    p.W2 = (double*)malloc(OUTPUT_SIZE * HIDDEN_SIZE * sizeof(double));\n",
    "    p.b2 = (double*)calloc(OUTPUT_SIZE, sizeof(double));\n",
    "\n",
    "    init_xavier(p.W1, INPUT_SIZE, HIDDEN_SIZE);\n",
    "    init_xavier(p.W2, HIDDEN_SIZE, OUTPUT_SIZE);\n",
    "    return p;\n",
    "}\n",
    "\n",
    "double hsum_avx(__m256d v) {\n",
    "    __m128d v128 = _mm_add_pd(_mm256_castpd256_pd128(v), _mm256_extractf128_pd(v, 1));\n",
    "    __m128d v64 = _mm_hadd_pd(v128, v128);\n",
    "    return _mm_cvtsd_f64(v64);\n",
    "}\n",
    "\n",
    "// --- Multiplicaciones Matriciales Paralelas (MatMul) ---\n",
    "\n",
    "/**\n",
    " * C = A * B. Paraleliza sobre las filas de A (i).\n",
    " */\n",
    "void matmul_avx(const double* A, const double* B, double* C, int m, int n, int p) {\n",
    "    #pragma omp parallel for \n",
    "    for (int i = 0; i < m; i++) { // Filas de la matriz de salida C (neuronas)\n",
    "        for (int j = 0; j < p; j++) { // Columnas de la matriz de salida C (batch size)\n",
    "            __m256d sum_vec = _mm256_setzero_pd();\n",
    "            double sum_scalar = 0.0;\n",
    "            int k;\n",
    "\n",
    "            for (k = 0; k < (n / AVX_DOUBLE_WIDTH) * AVX_DOUBLE_WIDTH; k += AVX_DOUBLE_WIDTH) {\n",
    "                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n",
    "                \n",
    "                double B_temp[AVX_DOUBLE_WIDTH];\n",
    "                B_temp[0] = B[(k + 0) * p + j];\n",
    "                B_temp[1] = B[(k + 1) * p + j];\n",
    "                B_temp[2] = B[(k + 2) * p + j];\n",
    "                B_temp[3] = B[(k + 3) * p + j];\n",
    "                __m256d b_vec = _mm256_loadu_pd(B_temp); \n",
    "\n",
    "                sum_vec = _mm256_fmadd_pd(a_vec, b_vec, sum_vec); \n",
    "            }\n",
    "            \n",
    "            sum_scalar = hsum_avx(sum_vec);\n",
    "\n",
    "            for (; k < n; k++) {\n",
    "                sum_scalar += A[i * n + k] * B[k * p + j];\n",
    "            }\n",
    "\n",
    "            C[i * p + j] = sum_scalar;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * C = A * B^T. Paraleliza sobre las filas de A (i) y las filas de B (j).\n",
    " */\n",
    "void matmul_Bt_avx(const double* A, const double* B, double* C, int m, int n, int p) {\n",
    "    #pragma omp parallel for collapse(2) \n",
    "    for (int i = 0; i < m; i++) { // Filas de A (neuronas de salida)\n",
    "        for (int j = 0; j < p; j++) { // Filas de B (neuronas de entrada)\n",
    "            __m256d sum_vec = _mm256_setzero_pd();\n",
    "            double sum_scalar = 0.0;\n",
    "            int k;\n",
    "            \n",
    "            for (k = 0; k < (n / AVX_DOUBLE_WIDTH) * AVX_DOUBLE_WIDTH; k += AVX_DOUBLE_WIDTH) {\n",
    "                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n",
    "                __m256d b_vec = _mm256_loadu_pd(&B[j * n + k]);\n",
    "                \n",
    "                sum_vec = _mm256_fmadd_pd(a_vec, b_vec, sum_vec); \n",
    "            }\n",
    "            \n",
    "            sum_scalar = hsum_avx(sum_vec);\n",
    "\n",
    "            for (; k < n; k++) {\n",
    "                sum_scalar += A[i * n + k] * B[j * n + k];\n",
    "            }\n",
    "            C[i * p + j] = sum_scalar;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * C = A^T * B. Paraleliza sobre las filas de C (i).\n",
    " */\n",
    "void matmul_At_avx(const double* A, const double* B, double* C, int m, int n, int p) {\n",
    "    #pragma omp parallel for \n",
    "    for (int i = 0; i < m; i++) { // Filas de C (neuronas)\n",
    "        int j;\n",
    "        for (j = 0; j < (p / AVX_DOUBLE_WIDTH) * AVX_DOUBLE_WIDTH; j += AVX_DOUBLE_WIDTH) { \n",
    "            __m256d c_vec = _mm256_setzero_pd();\n",
    "            for (int k = 0; k < n; k++) { \n",
    "                __m256d a_scalar_vec = _mm256_set1_pd(A[k * m + i]); \n",
    "                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n",
    "                \n",
    "                c_vec = _mm256_fmadd_pd(a_scalar_vec, b_vec, c_vec);\n",
    "            }\n",
    "            _mm256_storeu_pd(&C[i * p + j], c_vec);\n",
    "        }\n",
    "        for (int j_scalar = j; j_scalar < p; j_scalar++) {\n",
    "            double sum = 0.0;\n",
    "            for (int k = 0; k < n; k++) {\n",
    "                sum += A[k * m + i] * B[k * p + j_scalar];\n",
    "            }\n",
    "            C[i * p + j_scalar] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// --- Otras Operaciones Vectorizadas Paralelas ---\n",
    "\n",
    "void add_bias_avx(double* Z, const double* b, int rows, int cols) {\n",
    "    #pragma omp parallel for \n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        __m256d b_scalar_vec = _mm256_set1_pd(b[i]);\n",
    "        int j;\n",
    "        for (j = 0; j < (cols / AVX_DOUBLE_WIDTH) * AVX_DOUBLE_WIDTH; j += AVX_DOUBLE_WIDTH) {\n",
    "            __m256d z_vec = _mm256_loadu_pd(&Z[i * cols + j]);\n",
    "            z_vec = _mm256_add_pd(z_vec, b_scalar_vec);\n",
    "            _mm256_storeu_pd(&Z[i * cols + j], z_vec);\n",
    "        }\n",
    "        for (; j < cols; j++) {\n",
    "            Z[i * cols + j] += b[i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void relu_backward_avx(double* dZ, const double* Z, int size) {\n",
    "    __m256d zero_vec = _mm256_setzero_pd();\n",
    "    int i;\n",
    "    // Paraleliza sobre los elementos del vector\n",
    "    #pragma omp parallel for \n",
    "    for (i = 0; i < (size / AVX_DOUBLE_WIDTH) * AVX_DOUBLE_WIDTH; i += AVX_DOUBLE_WIDTH) {\n",
    "        __m256d dz_vec = _mm256_loadu_pd(&dZ[i]);\n",
    "        __m256d z_vec = _mm256_loadu_pd(&Z[i]);\n",
    "        \n",
    "        __m256d mask = _mm256_cmp_pd(z_vec, zero_vec, _CMP_GT_OS); \n",
    "        __m256d result_vec = _mm256_and_pd(dz_vec, mask);\n",
    "        \n",
    "        _mm256_storeu_pd(&dZ[i], result_vec);\n",
    "    }\n",
    "    // La limpieza escalar aquí puede dejarse secuencial o paralelizarse también, \n",
    "    // pero el bucle principal es el que da el beneficio.\n",
    "    for (; i < size; i++) {\n",
    "        if (Z[i] <= 0) dZ[i] = 0;\n",
    "    }\n",
    "}\n",
    "\n",
    "void update_params_avx(double* W, const double* dW, const double inv_m, int size) {\n",
    "    __m256d lr_vec = _mm256_set1_pd(LR * inv_m);\n",
    "    int i;\n",
    "    // Paraleliza sobre los elementos del vector W\n",
    "    #pragma omp parallel for \n",
    "    for (i = 0; i < (size / AVX_DOUBLE_WIDTH) * AVX_DOUBLE_WIDTH; i += AVX_DOUBLE_WIDTH) {\n",
    "        __m256d w_vec = _mm256_loadu_pd(&W[i]);\n",
    "        __m256d dw_vec = _mm256_loadu_pd(&dW[i]);\n",
    "        \n",
    "        __m256d step_vec = _mm256_mul_pd(lr_vec, dw_vec);\n",
    "        w_vec = _mm256_sub_pd(w_vec, step_vec);\n",
    "        \n",
    "        _mm256_storeu_pd(&W[i], w_vec);\n",
    "    }\n",
    "    for (; i < size; i++) {\n",
    "        W[i] -= LR * dW[i] * inv_m;\n",
    "    }\n",
    "}\n",
    "\n",
    "// --- FUNCIONES ESCALARES (Las dejamos secuenciales o con paralelismo implícito) ---\n",
    "\n",
    "void relu(double* Z, int size) {\n",
    "    #pragma omp parallel for \n",
    "    for (int i = 0; i < size; i++) {\n",
    "        if (Z[i] < 0) Z[i] = 0;\n",
    "    }\n",
    "}\n",
    "\n",
    "void softmax(double* Z, int rows, int cols) {\n",
    "    #pragma omp parallel for \n",
    "    for (int j = 0; j < cols; j++) { // Paraleliza sobre las columnas (muestras)\n",
    "        double max = Z[0 * cols + j];\n",
    "        for (int i = 1; i < rows; i++) {\n",
    "            if (Z[i * cols + j] > max) max = Z[i * cols + j];\n",
    "        }\n",
    "        double sum = 0.0;\n",
    "        for (int i = 0; i < rows; i++) {\n",
    "            Z[i * cols + j] = exp(Z[i * cols + j] - max); \n",
    "            sum += Z[i * cols + j];\n",
    "        }\n",
    "        for (int i = 0; i < rows; i++) {\n",
    "            Z[i * cols + j] /= sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void one_hot(const int* Y, double* Y_OH, int m_batch) {\n",
    "    // La inicialización se puede paralelizar\n",
    "    #pragma omp parallel for \n",
    "    for(int i=0; i<OUTPUT_SIZE * m_batch; i++) Y_OH[i] = 0.0;\n",
    "\n",
    "    // El resto es secuencial por su naturaleza de escritura indexada\n",
    "    for (int j = 0; j < m_batch; j++) {\n",
    "        int label = Y[j];\n",
    "        if (label >= 0 && label < OUTPUT_SIZE) {\n",
    "            Y_OH[label * m_batch + j] = 1.0;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "double get_accuracy(const double* A2, const int* Y, int m_batch) {\n",
    "    // Cálculo secuencial rápido, no necesita paralelismo\n",
    "    int correct_predictions = 0;\n",
    "    for (int j = 0; j < m_batch; j++) {\n",
    "        double max_val = -1.0;\n",
    "        int predicted_label = -1;\n",
    "        for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
    "            if (A2[i * m_batch + j] > max_val) {\n",
    "                max_val = A2[i * m_batch + j];\n",
    "                predicted_label = i;\n",
    "            }\n",
    "        }\n",
    "        if (predicted_label == Y[j]) {\n",
    "            correct_predictions++;\n",
    "        }\n",
    "    }\n",
    "    return (double)correct_predictions / m_batch;\n",
    "}\n",
    "\n",
    "double cross_entropy_loss(const double* A2, const int* Y, int m_batch) {\n",
    "    // Cálculo secuencial rápido, no necesita paralelismo\n",
    "    double loss = 0.0;\n",
    "    for (int j = 0; j < m_batch; j++) {\n",
    "        int true_label = Y[j];\n",
    "        double prob = A2[true_label * m_batch + j];\n",
    "        if (prob < 1e-12) prob = 1e-12; \n",
    "        loss += -log(prob);\n",
    "    }\n",
    "    return loss / m_batch;\n",
    "}\n",
    "\n",
    "// --- BUCLE DE ENTRENAMIENTO PRINCIPAL ---\n",
    "\n",
    "void train(Params p, double* X_train, int* Y_train) {\n",
    "    // ... (Inicialización de buffers) ...\n",
    "    double* Z1 = malloc(HIDDEN_SIZE * BATCH_SIZE * sizeof(double));\n",
    "    double* A1 = malloc(HIDDEN_SIZE * BATCH_SIZE * sizeof(double));\n",
    "    double* Z2 = malloc(OUTPUT_SIZE * BATCH_SIZE * sizeof(double));\n",
    "    double* dZ2 = malloc(OUTPUT_SIZE * BATCH_SIZE * sizeof(double));\n",
    "    double* dW2 = malloc(OUTPUT_SIZE * HIDDEN_SIZE * sizeof(double));\n",
    "    double* db2 = malloc(OUTPUT_SIZE * sizeof(double));\n",
    "    double* dA1 = malloc(HIDDEN_SIZE * BATCH_SIZE * sizeof(double));\n",
    "    double* dW1 = malloc(HIDDEN_SIZE * INPUT_SIZE * sizeof(double));\n",
    "    double* db1 = malloc(HIDDEN_SIZE * sizeof(double));\n",
    "    double* Y_batch_oh = malloc(OUTPUT_SIZE * BATCH_SIZE * sizeof(double));\n",
    "\n",
    "    int num_batches = M_TRAIN / BATCH_SIZE;\n",
    "\n",
    "    printf(\"\\n--- Inicio del Entrenamiento OpenMP ---\\n\");\n",
    "    printf(\"Arquitectura MLP: %d --> %d neuronas --> %d neuronas\\n\", INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE);\n",
    "\n",
    "    for (int epoch = 0; epoch < EPOCHS; epoch++) {\n",
    "        int correct = 0;\n",
    "        double epoch_loss = 0.0;\n",
    "        clock_t ep_start = clock();\n",
    "\n",
    "        // El bucle de batches permanece secuencial, solo las operaciones internas se paralelizan.\n",
    "        for (int b = 0; b < num_batches; b++) {\n",
    "            \n",
    "            // 1. Extracción del Batch\n",
    "            double* X_batch_ptr = malloc(INPUT_SIZE * BATCH_SIZE * sizeof(double));\n",
    "            // Esta copia (memcpy) es rápida, la dejamos secuencial\n",
    "            for(int i=0; i<INPUT_SIZE; i++) {\n",
    "                memcpy(&X_batch_ptr[i * BATCH_SIZE], \n",
    "                       &X_train[i * M_TRAIN + b * BATCH_SIZE], \n",
    "                       BATCH_SIZE * sizeof(double));\n",
    "            }\n",
    "            int* Y_batch_ptr = &Y_train[b * BATCH_SIZE];\n",
    "\n",
    "            // 2. FORWARD PROPAGATION (Todas las funciones MatMul están ahora paralelizadas con OMP)\n",
    "            matmul_avx(p.W1, X_batch_ptr, Z1, HIDDEN_SIZE, INPUT_SIZE, BATCH_SIZE);\n",
    "            add_bias_avx(Z1, p.b1, HIDDEN_SIZE, BATCH_SIZE); \n",
    "            \n",
    "            memcpy(A1, Z1, HIDDEN_SIZE * BATCH_SIZE * sizeof(double));\n",
    "            relu(A1, HIDDEN_SIZE * BATCH_SIZE); // Paralelizado\n",
    "\n",
    "            matmul_avx(p.W2, A1, Z2, OUTPUT_SIZE, HIDDEN_SIZE, BATCH_SIZE);\n",
    "            add_bias_avx(Z2, p.b2, OUTPUT_SIZE, BATCH_SIZE); \n",
    "\n",
    "            softmax(Z2, OUTPUT_SIZE, BATCH_SIZE); // Paralelizado\n",
    "\n",
    "            // 3. CÁLCULO DE PÉRDIDA Y ACCURACY (Secuencial)\n",
    "            epoch_loss += cross_entropy_loss(Z2, Y_batch_ptr, BATCH_SIZE);\n",
    "            correct += get_accuracy(Z2, Y_batch_ptr, BATCH_SIZE) * BATCH_SIZE;\n",
    "\n",
    "            // 4. BACKWARD PROPAGATION\n",
    "            one_hot(Y_batch_ptr, Y_batch_oh, BATCH_SIZE);\n",
    "            \n",
    "            // dZ2 = A2 - Y_OH (Se puede paralelizar, pero es muy rápido)\n",
    "            #pragma omp parallel for \n",
    "            for(int i=0; i<OUTPUT_SIZE * BATCH_SIZE; i++) dZ2[i] = Z2[i] - Y_batch_oh[i];\n",
    "\n",
    "            // dW2 = (1/m) * dZ2 * A1^T (Paralelizado OMP/AVX)\n",
    "            matmul_Bt_avx(dZ2, A1, dW2, OUTPUT_SIZE, BATCH_SIZE, HIDDEN_SIZE);\n",
    "            \n",
    "            // db2 = (1/m) * sum(dZ2) (Se puede usar reducción, pero el cálculo secuencial es simple)\n",
    "            for(int i=0; i<OUTPUT_SIZE; i++) {\n",
    "                double sum = 0;\n",
    "                #pragma omp parallel for reduction(+:sum) \n",
    "                for(int j=0; j<BATCH_SIZE; j++) sum += dZ2[i * BATCH_SIZE + j];\n",
    "                db2[i] = sum;\n",
    "            }\n",
    "\n",
    "            // dA1 = W2^T * dZ2 (Paralelizado OMP/AVX)\n",
    "            matmul_At_avx(p.W2, dZ2, dA1, HIDDEN_SIZE, OUTPUT_SIZE, BATCH_SIZE);\n",
    "\n",
    "            // dZ1 = dA1 * ReLU'(Z1) (Paralelizado OMP/AVX)\n",
    "            relu_backward_avx(dA1, Z1, HIDDEN_SIZE * BATCH_SIZE); \n",
    "\n",
    "            // dW1 = (1/m) * dZ1 * X^T (Paralelizado OMP/AVX)\n",
    "            matmul_Bt_avx(dA1, X_batch_ptr, dW1, HIDDEN_SIZE, BATCH_SIZE, INPUT_SIZE);\n",
    "            \n",
    "            // db1 = (1/m) * sum(dZ1) (Paralelizado con reducción)\n",
    "            for(int i=0; i<HIDDEN_SIZE; i++) {\n",
    "                double sum = 0;\n",
    "                #pragma omp parallel for reduction(+:sum) \n",
    "                for(int j=0; j<BATCH_SIZE; j++) sum += dA1[i * BATCH_SIZE + j];\n",
    "                db1[i] = sum;\n",
    "            }\n",
    "\n",
    "            // 5. UPDATE PARAMETERS (Paralelizado OMP/AVX)\n",
    "            double inv_m = 1.0 / BATCH_SIZE;\n",
    "            \n",
    "            update_params_avx(p.W2, dW2, inv_m, OUTPUT_SIZE * HIDDEN_SIZE);\n",
    "            for(int i=0; i<OUTPUT_SIZE; i++) p.b2[i] -= LR * db2[i] * inv_m; \n",
    "            \n",
    "            update_params_avx(p.W1, dW1, inv_m, HIDDEN_SIZE * INPUT_SIZE);\n",
    "            for(int i=0; i<HIDDEN_SIZE; i++) p.b1[i] -= LR * db1[i] * inv_m; \n",
    "\n",
    "            free(X_batch_ptr);\n",
    "        }\n",
    "        \n",
    "        clock_t ep_end = clock();\n",
    "        double avg_epoch_loss = epoch_loss / num_batches; \n",
    "        \n",
    "        printf(\"Epoch %d/%d - Loss: %.4f - Acc: %.2f%% - Tiempo: %.2fs\\n\", \n",
    "               epoch+1, EPOCHS, avg_epoch_loss, (double)correct * 100.0 / M_TRAIN, get_time_diff(ep_start, ep_end)/10);\n",
    "    }\n",
    "\n",
    "    // ... (Liberación de Buffers) ...\n",
    "    free(Z1); free(A1); free(Z2); free(dZ2); free(dW2); free(db2);\n",
    "    free(dA1); free(dW1); free(db1); free(Y_batch_oh);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    double* X_train = malloc(INPUT_SIZE * M_TRAIN * sizeof(double));\n",
    "    int* Y_train = malloc(M_TRAIN * sizeof(int));\n",
    "\n",
    "    if (!X_train || !Y_train) {\n",
    "        fprintf(stderr, \"Error de memoria.\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    printf(\"Cargando datos MNIST...\\n\");\n",
    "    load_data(X_train, Y_train);\n",
    "\n",
    "    printf(\"----------------------------------------\\n\");\n",
    "    printf(\"Arquitectura MLP: %d --> %d neuronas (Oculta) --> %d neuronas (Salida).\\n\", \n",
    "           INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE);\n",
    "    printf(\"----------------------------------------\\n\");\n",
    "    \n",
    "    Params p = init_params();\n",
    "    \n",
    "    clock_t start = clock();\n",
    "    \n",
    "    train(p, X_train, Y_train);\n",
    "    \n",
    "    clock_t end = clock();\n",
    "    double total_time = get_time_diff(start, end);\n",
    "\n",
    "    printf(\"\\n----------------------------------------\\n\");\n",
    "    printf(\"Entrenamiento Finalizado.\\n\");\n",
    "    printf(\"Tiempo Total OpenMP: %.2f segundos\\n\", total_time/10);\n",
    "    printf(\"----------------------------------------\\n\");\n",
    "\n",
    "    // Liberación de Parámetros y Datos\n",
    "    free(X_train); free(Y_train);\n",
    "    free(p.W1); free(p.b1); free(p.W2); free(p.b2);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
